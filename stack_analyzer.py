import os
import re
import json
import argparse
from dataclasses import dataclass
from typing import List, Dict, Optional, Set

@dataclass
class Function:
    name: str
    file: str

@dataclass
class StackUsage:
    function: Function
    usage: int
    type: str

@dataclass
class CallGraph:
    function: Function
    calls: list[Function]

@dataclass
class CflowLine:
    function: Function
    indent_level: int

@dataclass
class CalledFunction:
    function: Function
    total_usage: int

@dataclass
class FunctionReport:
    function: Function
    self_usage: int
    total_usage: int
    type: str
    called_functions: List[CalledFunction]

def parse_su_file(file_path: str) -> List[StackUsage]:
    """
    Analyzes a .su file to obtain stack usage information.
    
    Args:
        file_path: Path to the .su file to be analyzed
        
    Returns:
        List of StackUsage objects containing stack usage information
    """
    stack_usages = []

    with open(file_path, 'r') as file:
        for line in file:
            # Expected format: file:line:col:function_name bytes type
            match = re.match(r'([^:]+):(\d+):(\d+):(\S+)\s+(\d+)\s+(\S+)', line.strip())
            if match:
                source_file, _, _, function_name, usage, usage_type = match.groups()
                function = Function(file=source_file, name=function_name)
                stack_usage = StackUsage(
                    function=function,
                    usage=int(usage),
                    type=usage_type
                )
                stack_usages.append(stack_usage)

    return stack_usages

def find_su_files(directory: str) -> List[StackUsage]:
    """
    Recursively navigates through a directory looking for .su files and extracts stack usage information.
    
    Args:
        directory: Root directory to start the search
        
    Returns:
        List of StackUsage objects containing stack usage information from all files found
    """
    all_stack_usages = []
    
    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith('.su'):
                file_path = os.path.join(root, file)
                try:
                    stack_usages = parse_su_file(file_path)
                    all_stack_usages.extend(stack_usages)
                except Exception as e:
                    print(f"Error processing {file_path}: {e}")
    
    return all_stack_usages

def parse_cflow_line(line: str) -> Optional[CflowLine]:
    """
    Analyzes a line from the cflow file to extract function call information.
    
    Args:
        line: Line from the cflow file
        
    Returns:
        CflowLine object containing line information, or None if the line doesn't contain valid information
    """
    match = re.match(r'{\s*(\d+)\}\s+(\S+)\(\).*at\s+([^:]+):(\d+)', line)
    if match:
        indent_level = int(match.group(1))
        function_name = match.group(2)
        source_file = match.group(3)
        return CflowLine(
            indent_level=indent_level,
            function=Function(name=function_name, file=source_file)
        )
    return None

def parse_cflow_file(file_path: str) -> List[CallGraph]:
    """
    Analyzes a file generated by the cflow tool to extract the function call graph.
    
    Args:
        file_path: Path to the cflow file to be analyzed
        
    Returns:
        List of CallGraph objects representing the call graph
    """
    call_graphs = []
    call_stack = []

    with open(file_path, 'r') as file:
        for line in file:
            parsed = parse_cflow_line(line)
            if not parsed:
                continue

            current_function = parsed.function

            # Adjust call stack based on indentation level
            while len(call_stack) > parsed.indent_level:
                call_stack.pop()

            # Create CallGraph entry for the parent function if it exists
            if call_stack and parsed.indent_level > 0:
                parent = call_stack[-1]
                # Find if we already have a CallGraph for this parent
                parent_graph = next((cg for cg in call_graphs if cg.function == parent), None)

                if parent_graph:
                    # Check if this function call is already in the parent's calls
                    if not any(f.name == current_function.name and 
                               f.file == current_function.file for f in parent_graph.calls):
                        parent_graph.calls.append(current_function)
                else:
                    # Create new CallGraph for this parent
                    call_graphs.append(CallGraph(function=parent, calls=[current_function]))

            # Add current function to call stack
            call_stack.append(current_function)

            # If this is a new root function, create a CallGraph for it
            if parsed.indent_level == 0 and not any(cg.function == current_function for cg in call_graphs):
                call_graphs.append(CallGraph(function=current_function, calls=[]))

    return call_graphs

def calculate_total_stack_usage(function: Function, call_graph_map: Dict[str, CallGraph], 
                               stack_usage_map: Dict[str, int], visited: Set[str] = None) -> int:
    """
    Calculates the total stack usage for a function, considering recursive calls.
    
    Args:
        function: Function to calculate stack usage for
        call_graph_map: Mapping of functions to their call graphs
        stack_usage_map: Mapping of functions to their stack usage
        visited: Set of already visited functions to avoid infinite loops
        
    Returns:
        Total stack usage in bytes
    """
    if visited is None:
        visited = set()

    # Create a unique key for the function
    function_key = f"{function.name}:{function.file}"

    # If we've already visited this function, return 0 to avoid double counting
    if function_key in visited:
        return 0

    # Mark this function as visited
    visited.add(function_key)

    # Get the stack usage for this function
    base_usage = stack_usage_map.get(function_key, 0)

    # Get the call graph for this function
    call_graph = call_graph_map.get(function_key)
    if not call_graph:
        return base_usage

    # Calculate the maximum stack usage of any call path
    max_call_path_usage = 0
    for called_function in call_graph.calls:
        called_key = f"{called_function.name}:{called_function.file}"
        # Skip self-recursive calls as they're already accounted for in the base usage
        if called_key != function_key:
            call_usage = calculate_total_stack_usage(called_function, call_graph_map, stack_usage_map, visited.copy())
            max_call_path_usage = max(max_call_path_usage, call_usage)

    return base_usage + max_call_path_usage

def generate_json_report(stack_usages: List[StackUsage], call_graphs: List[CallGraph]) -> List[FunctionReport]:
    """
    Generates a JSON report with stack analysis data.
    
    Args:
        stack_usages: List of stack usage information
        call_graphs: List of call graph information
        
    Returns:
        List of FunctionReport objects with stack usage information for each function
    """
    # Create mapping for easier lookup
    stack_usage_map = {f"{su.function.name}:{su.function.file}": su.usage for su in stack_usages}
    stack_type_map = {f"{su.function.name}:{su.function.file}": su.type for su in stack_usages}
    call_graph_map = {f"{cg.function.name}:{cg.function.file}": cg for cg in call_graphs}

    # Create the report data
    report_data = []

    for su in stack_usages:
        # Calculate total stack usage for this function
        total_usage = calculate_total_stack_usage(su.function, call_graph_map, stack_usage_map)

        # Get the list of called functions
        function_key = f"{su.function.name}:{su.function.file}"
        call_graph = call_graph_map.get(function_key)
        called_functions = []

        if call_graph:
            for called_func in call_graph.calls:
                called_key = f"{called_func.name}:{called_func.file}"
                # Calculate total usage for called function
                called_total_usage = calculate_total_stack_usage(called_func, call_graph_map, stack_usage_map)
                called_functions.append(CalledFunction(
                    function=called_func,
                    total_usage=called_total_usage
                ))

        # Create the entry for this function
        entry = FunctionReport(
            function=su.function,
            self_usage=su.usage,
            total_usage=total_usage,
            type=su.type,
            called_functions=called_functions
        )

        report_data.append(entry)

    # Sort by total stack usage (descending)
    # Changed to sort first by function name and then by file
    report_data.sort(key=lambda x: (x.function.name, x.function.file))

    return report_data

def save_json_report(report_data: List[FunctionReport], output_path: str):
    """
    Saves the JSON report to a file.
    
    Args:
        report_data: List of report data
        output_path: Path where the file will be saved
    """
    # Sort report_data before converting to dictionaries
    report_data.sort(key=lambda x: (x.function.file, x.function.name))

    # Convert dataclass objects to dictionaries for JSON serialization
    json_data = [
        {
            "file": report.function.file,
            "function": report.function.name,
            "self_usage": report.self_usage,
            "total_usage": report.total_usage,
            "type": report.type,
            "called_functions": [
                {
                    "file": called.function.file,
                    "function": called.function.name,
                    "total_usage": called.total_usage
                }
                # Sort called_functions before adding to dictionary
                for called in sorted(report.called_functions, 
                    key=lambda x: (x.function.file, x.function.name)
                )
            ]
        }
        for report in report_data
    ]

    with open(output_path, 'w') as file:
        json.dump(json_data, file, indent=2)

def main():
    """
    Main function that processes command-line arguments and executes stack usage analysis.
    """
    parser = argparse.ArgumentParser(description='Analyze stack usage from compiler output and cflow files')
    parser.add_argument('--su-dir', required=True, help='Directory to recursively search for .su files')
    parser.add_argument('--cflow-file', required=True,
        help='Path to the cflow output file (options --print-level and --format=gnu are required for good parsing)'
    )
    parser.add_argument('--output', default='stack_analysis.json', help='Path to output JSON report file (default: %(default)s)')

    args = parser.parse_args()

    # Find and parse .su files
    stack_usages = find_su_files(args.su_dir)
    print(f"Found {len(stack_usages)} stack usage records")

    # Parse cflow file
    call_graphs = parse_cflow_file(args.cflow_file)
    print(f"Found {len(call_graphs)} call graph entries")

    # Generate JSON report
    report_data = generate_json_report(stack_usages, call_graphs)

    # Save to output file
    save_json_report(report_data, args.output)
    print(f"JSON report saved to {args.output}")

if __name__ == "__main__":
    main()
